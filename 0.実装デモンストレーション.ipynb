{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuracode/hsprogramming/blob/main/0.%E5%AE%9F%E8%A3%85%E3%83%87%E3%83%A2%E3%83%B3%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUI5hEP6OC7h"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision qrcode gradio -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio, qrcode, Pillow(Image)に加えて、\n",
        "# メモリ上でデータをファイルのように扱うための`BytesIO`をインポートします。\n",
        "import gradio as gr\n",
        "import qrcode\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# 入力されたテキストからQRコード画像を生成する`generate_qr`関数を定義します。\n",
        "def generate_qr(text):\n",
        "    # `qrcode.make()`を使い、テキストをQRコードの画像オブジェクトに変換します。\n",
        "    qr_img = qrcode.make(text)\n",
        "\n",
        "    # --- Colab等の環境でより安定して動作させるための処理 ---\n",
        "    # `BytesIO`を使い、画像データを一時的に保存するためのメモリ領域(`buf`)を用意します。\n",
        "    buf = BytesIO()\n",
        "    # 生成したQRコード画像を、PNG形式でメモリ領域(`buf`)に書き込みます。\n",
        "    qr_img.save(buf, format=\"PNG\")\n",
        "    # 書き込んだデータを最初から読み込めるように、メモリ上のカーソルを先頭に戻します。\n",
        "    buf.seek(0)\n",
        "    # メモリ領域から画像データを読み込み、改めてPillowの画像オブジェクトとして開きます。\n",
        "    img = Image.open(buf)\n",
        "\n",
        "    # 安全な形式に変換された画像データを返します。\n",
        "    return img\n",
        "\n",
        "# GradioのInterfaceを使い、Web UIを設計します。\n",
        "demo = gr.Interface(fn=generate_qr, inputs=\"text\", outputs=\"image\")\n",
        "\n",
        "# 作成したUIを、外部からアクセス可能な公開URLで起動します。\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "okZk_LZdHD_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeVSKD2_PDhM"
      },
      "outputs": [],
      "source": [
        "# Gradioライブラリと、画像生成AIを簡単に扱うための`diffusers`ライブラリをインポートします。\n",
        "import gradio as gr\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "# stabilityaiが提供する学習済みの画像生成AIモデル（Stable Diffusion）を読み込みます。\n",
        "# 初回実行時は、モデルのダウンロードに数分かかることがあります。\n",
        "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\")\n",
        "# 読み込んだAIモデルをGPUに転送します。これにより、画像生成が高速になります。\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# プロンプト（テキストの指示）を受け取り、画像を生成する関数を定義します。\n",
        "def generate_image(prompt):\n",
        "    # AIモデル(`pipe`)にプロンプトを渡し、画像生成を実行します。\n",
        "    # 結果の中から最初の画像(`.images[0]`)を取り出します。\n",
        "    image = pipe(prompt).images[0]\n",
        "    # 生成された画像を返します。\n",
        "    return image\n",
        "\n",
        "# GradioのInterfaceを使い、Web UIを設計します。\n",
        "demo = gr.Interface(fn=generate_image,\n",
        "                    inputs=\"text\",\n",
        "                    outputs=\"image\",\n",
        "                    # `title=`でUIのタイトルを、`description=`で説明文を設定できます。\n",
        "                    title=\"AIイラストレーター\",\n",
        "                    description=\"好きな言葉（プロンプト）を入力して、画像を作ってみよう！\")\n",
        "\n",
        "# 作成したUI(`demo`)を、外部からアクセス可能な公開URLで起動します。\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72FDbzfyNxmO"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリをすべてインポート\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.models import resnet50\n",
        "import requests\n",
        "\n",
        "# --- AIモデルとラベルの準備 ---\n",
        "# この準備は一度だけ行います\n",
        "try:\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIモデルの準備が完了しました。\")\n",
        "except Exception as e:\n",
        "    print(f\"AIモデルの準備中にエラーが発生しました: {e}\")\n",
        "    model = None\n",
        "    labels = None\n",
        "\n",
        "# --- 1. 画像加工のロジック（前回のコードと同じ） ---\n",
        "def image_processing(img, filter_type, blur_level, watermark_text):\n",
        "    if img is None:\n",
        "        return None, \"画像をアップロードしてください。\"\n",
        "    processed_img = img.copy()\n",
        "    if filter_type == \"白黒\":\n",
        "        processed_img = processed_img.convert('L')\n",
        "    elif filter_type == \"90度回転\":\n",
        "        processed_img = processed_img.rotate(90, expand=True)\n",
        "    if blur_level > 0:\n",
        "        processed_img = processed_img.filter(ImageFilter.GaussianBlur(radius=blur_level))\n",
        "    if watermark_text:\n",
        "        draw = ImageDraw.Draw(processed_img)\n",
        "        draw.text((10, 10), watermark_text, fill=\"white\", stroke_width=1, stroke_fill=\"black\")\n",
        "    return processed_img, f\"処理完了：{filter_type}\"\n",
        "\n",
        "# --- 2. AIによる画像分析のロジック ---\n",
        "# (教材のコードを関数として整理)\n",
        "@torch.no_grad()\n",
        "def predict(input_img):\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    # PIL ImageをPyTorchが扱えるTensorに変換\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # 白黒画像の場合\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    # 推論の実行\n",
        "    output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    # 結果を{ラベル: 確率}の辞書形式で返す\n",
        "    return {labels[i]: float(probs[i]) for i in range(1000)}\n",
        "\n",
        "# --- GradioのUIを構築 ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 総合画像処理アプリ\")\n",
        "    gr.Markdown(\"手動での画像加工と、AIによる画像分析ができます。\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- タブ1: 画像加工 ---\n",
        "        with gr.TabItem(\"画像加工\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    proc_input = gr.Image(type=\"pil\", label=\"加工したい画像をアップロード\")\n",
        "                    filter_radio = gr.Radio([\"なし\", \"白黒\", \"90度回転\"], label=\"フィルターを選択\", value=\"なし\")\n",
        "                    blur_slider = gr.Slider(0, 10, value=0, label=\"ぼかしの強さ\")\n",
        "                    watermark_input = gr.Textbox(label=\"透かし文字\")\n",
        "                    proc_btn = gr.Button(\"画像処理を実行\")\n",
        "                with gr.Column():\n",
        "                    proc_output = gr.Image(label=\"加工後の画像\")\n",
        "                    proc_status = gr.Textbox(label=\"処理ステータス\")\n",
        "            proc_btn.click(\n",
        "                fn=image_processing,\n",
        "                inputs=[proc_input, filter_radio, blur_slider, watermark_input],\n",
        "                outputs=[proc_output, proc_status]\n",
        "            )\n",
        "\n",
        "        # --- タブ2: AI画像分析 ---\n",
        "        with gr.TabItem(\"AI画像分析\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ai_input = gr.Image(type=\"pil\", label=\"分析したい画像をアップロード\")\n",
        "                    ai_btn = gr.Button(\"AI分析を実行\")\n",
        "                with gr.Column():\n",
        "                    ai_output = gr.Label(num_top_classes=5, label=\"分析結果\")\n",
        "            ai_btn.click(\n",
        "                fn=predict,\n",
        "                inputs=ai_input,\n",
        "                outputs=ai_output\n",
        "            )\n",
        "\n",
        "# 必要なライブラリのインストールを促すメッセージ\n",
        "print(\"\\nもし 'torch' や 'torchvision' がないというエラーが出たら、!pip install torch torchvision を実行してください。\")\n",
        "# アプリケーションの起動\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c2mNwwx7SyNu"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# 2コマ目・改：AIの思考を覗く！リアルタイム物体認識\n",
        "# ================================================================\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ1＆2：準備（初回と同じ）\n",
        "# ----------------------------------------------------------------\n",
        "!pip install transformers torch gradio --quiet\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ3：AIモデルの読み込み（初回と同じ）\n",
        "# ----------------------------------------------------------------\n",
        "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ4：AIの「思考」を可視化する「命令」を作る\n",
        "# ----------------------------------------------------------------\n",
        "# 予測結果のリストを、GradioのLabelコンポーネントが扱える形式（辞書）に変換する\n",
        "# ----------------------------------------------------------------\n",
        "def classify_image_realtime(image):\n",
        "    # 画像が入力されていない場合はNoneを返す\n",
        "    if image is None:\n",
        "        return None\n",
        "\n",
        "    predictions = image_classifier(image)\n",
        "\n",
        "    # 予測結果を {ラベル名: 確信度スコア} の辞書形式に変換する\n",
        "    # 上位3件だけを取り出す\n",
        "    result_dict = {p['label']: p['score'] for p in predictions[:10]}\n",
        "    return result_dict\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ5：ライブカメラ対応の操作パネルを起動する\n",
        "# ----------------------------------------------------------------\n",
        "# inputsにWebカメラを指定し、live=True に設定することでリアルタイム処理が実現する\n",
        "# ----------------------------------------------------------------\n",
        "gr.Interface(fn=classify_image_realtime,\n",
        "             inputs=gr.Image(sources=[\"webcam\"], type=\"pil\", label=\"Webカメラ\"),\n",
        "             outputs=gr.Label(num_top_classes=10, label=\"AIの認識結果（トップ10）\"),\n",
        "             title=\"👀 AIの思考を覗く！リアルタイム物体認識カメラ\",\n",
        "             description=\"Webカメラに身の回りのものを写してみてください。AIが何を認識しているか、その確信度と一緒にリアルタイムで表示します。\",\n",
        "             live=True).launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG6JpuoiMzXS"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリをすべてインポート\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.models import resnet50\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "# --- AIモデルとラベルの準備 ---\n",
        "# この準備は一度だけ行います\n",
        "try:\n",
        "    # Image Classification model\n",
        "    image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "    # ResNet50 for image analysis\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIモデルの準備が完了しました。\")\n",
        "except Exception as e:\n",
        "    print(f\"AIモデルの準備中にエラーが発生しました: {e}\")\n",
        "    image_classifier = None\n",
        "    model = None\n",
        "    labels = None\n",
        "\n",
        "# --- 1. 画像加工のロジック ---\n",
        "def image_processing(img, filter_type, blur_level, watermark_text):\n",
        "    if img is None:\n",
        "        return None, \"画像をアップロードしてください。\"\n",
        "    processed_img = img.copy()\n",
        "    if filter_type == \"白黒\":\n",
        "        processed_img = processed_img.convert('L')\n",
        "    elif filter_type == \"90度回転\":\n",
        "        processed_img = processed_img.rotate(90, expand=True)\n",
        "    if blur_level > 0:\n",
        "        processed_img = processed_img.filter(ImageFilter.GaussianBlur(radius=blur_level))\n",
        "    if watermark_text:\n",
        "        draw = ImageDraw.Draw(processed_img)\n",
        "        draw.text((10, 10), watermark_text, fill=\"white\", stroke_width=1, stroke_fill=\"black\")\n",
        "    return processed_img, f\"処理完了：{filter_type}\"\n",
        "\n",
        "# --- 2. AIによる画像分析のロジック ---\n",
        "@torch.no_grad()\n",
        "def predict(input_img):\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # 白黒画像の場合\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    return {labels[i]: float(probs[i]) for i in range(1000)}\n",
        "\n",
        "# --- 3. AIの「思考」を可視化する「命令」を作る (リアルタイム物体認識) ---\n",
        "def classify_image_realtime(image):\n",
        "    if image_classifier is None or image is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    predictions = image_classifier(image)\n",
        "\n",
        "    result_dict = {p['label']: p['score'] for p in predictions[:10]}\n",
        "    return result_dict\n",
        "\n",
        "# --- GradioのUIを構築 ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 総合画像処理アプリ\")\n",
        "    gr.Markdown(\"手動での画像加工、AIによる画像分析、リアルタイム物体認識ができます。\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- タブ1: 画像加工 ---\n",
        "        with gr.TabItem(\"画像加工\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    proc_input = gr.Image(type=\"pil\", label=\"加工したい画像をアップロード\")\n",
        "                    filter_radio = gr.Radio([\"なし\", \"白黒\", \"90度回転\"], label=\"フィルターを選択\", value=\"なし\")\n",
        "                    blur_slider = gr.Slider(0, 10, value=0, label=\"ぼかしの強さ\")\n",
        "                    watermark_input = gr.Textbox(label=\"透かし文字\")\n",
        "                    proc_btn = gr.Button(\"画像処理を実行\")\n",
        "                with gr.Column():\n",
        "                    proc_output = gr.Image(label=\"加工後の画像\")\n",
        "                    proc_status = gr.Textbox(label=\"処理ステータス\")\n",
        "            proc_btn.click(\n",
        "                fn=image_processing,\n",
        "                inputs=[proc_input, filter_radio, blur_slider, watermark_input],\n",
        "                outputs=[proc_output, proc_status]\n",
        "            )\n",
        "\n",
        "        # --- タブ2: AI画像分析 ---\n",
        "        with gr.TabItem(\"AI画像分析\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ai_input = gr.Image(type=\"pil\", label=\"分析したい画像をアップロード\")\n",
        "                    ai_btn = gr.Button(\"AI分析を実行\")\n",
        "                with gr.Column():\n",
        "                    ai_output = gr.Label(num_top_classes=5, label=\"分析結果\")\n",
        "            ai_btn.click(\n",
        "                fn=predict,\n",
        "                inputs=ai_input,\n",
        "                outputs=ai_output\n",
        "            )\n",
        "\n",
        "        # --- タブ3: リアルタイム物体認識 ---\n",
        "        with gr.TabItem(\"リアルタイム物体認識\"):\n",
        "             with gr.Row():\n",
        "                 with gr.Column():\n",
        "                     realtime_input = gr.Image(sources=[\"webcam\"], type=\"pil\", label=\"Webカメラ\")\n",
        "                     # realtime_btn = gr.Button(\"AI分析を実行 (リアルタイム)\") # ボタンは不要なので削除\n",
        "                 with gr.Column():\n",
        "                     realtime_output = gr.Label(num_top_classes=10, label=\"AIの認識結果（トップ10）\")\n",
        "             # Use change() for real-time updates from webcam\n",
        "             realtime_input.change(\n",
        "                 fn=classify_image_realtime,\n",
        "                 inputs=realtime_input,\n",
        "                 outputs=realtime_output,\n",
        "                 live=True # Add live=True for real-time updates\n",
        "             )\n",
        "\n",
        "\n",
        "# 必要なライブラリのインストールを促すメッセージ\n",
        "print(\"\\nもし 'torch' や 'torchvision' がないというエラーが出たら、!pip install torch torchvision を実行してください。\")\n",
        "# アプリケーションの起動\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p99xOJu6BCe8"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリをインポートします\n",
        "# gradio: Web UIを簡単に作るためのライブラリ\n",
        "# PIL (Pillow): 画像を加工するためのライブラリ\n",
        "# numpy: 数値計算、特にAIでよく使われるライブラリ\n",
        "# その他: AIモデルを動かすためのライブラリ\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "# --- ここからAIの準備 (この部分は完成しています) ---\n",
        "# 授業で使ったResNet50モデルとImageNetラベルを準備します\n",
        "# この部分は一度だけ実行されます\n",
        "try:\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIモデルの準備OK！\")\n",
        "except Exception as e:\n",
        "    print(\"AIモデルの準備中にエラーが発生しました:\", e)\n",
        "    model = None\n",
        "    labels = None\n",
        "# --- AIの準備ここまで ---\n",
        "\n",
        "\n",
        "# --- 関数を定義するエリア ---\n",
        "\n",
        "# 【課題１】画像加工用の関数を完成させよう！\n",
        "# 1コマ目の最後に作った「白黒フィルター」の処理を思い出して書いてみよう！\n",
        "def image_filter(input_img):\n",
        "    print(\"画像加工ボタンが押されました！\")\n",
        "    if input_img is None:\n",
        "        return None # 画像がなければ何もしない\n",
        "\n",
        "    # ▼▼▼ ここに、Pillowを使った画像処理コードを追加しよう ▼▼▼\n",
        "    # ヒント: input_img.convert('L') を使うと白黒にできます\n",
        "\n",
        "    processed_img = input_img.convert('L') # 今はまだ何もしないので、この行を書き換えよう！\n",
        "\n",
        "    # ▲▲▲ ここまで ▲▲▲\n",
        "\n",
        "    return processed_img\n",
        "\n",
        "\n",
        "# 【課題２】AI分析用の関数を完成させよう！\n",
        "# 2コマ目に体験した「AIによる画像判定」のコードを参考に、中身を完成させよう！\n",
        "def predict_image(input_img):\n",
        "    print(\"AI分析ボタンが押されました！\")\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    # ▼▼▼ ここに、AIに画像を分析させるコードを追加しよう ▼▼▼\n",
        "    # ヒント: 教材『3.Gradio(Webインタフェース)の基本.ipynb』の最後の部分を参考にしよう\n",
        "    # 手順１：画像の前処理 (リサイズ、Tensorに変換、正規化)\n",
        "    # 手順２：AIによる推論 (model(img) を呼び出す)\n",
        "    # 手順３：結果を整形して、returnで返す\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # 白黒画像の場合\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    # 推論の実行\n",
        "    with torch.no_grad():\n",
        "        output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    # 結果を{ラベル: 確率}の辞書形式で返す\n",
        "    result = {labels[i]: float(probs[i]) for i in range(1000)} # 今はまだダミーのデータなので、この行を書き換えよう！\n",
        "\n",
        "    # ▲▲▲ ここまで ▲▲▲\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- Web UIを作るエリア (この部分は完成しています) ---\n",
        "# gr.Blocks() を使うと、より自由にUIを組み立てられます\n",
        "with gr.Blocks() as demo:\n",
        "    # アプリ全体のタイトル\n",
        "    gr.Markdown(\"# オリジナル画像加工＆AI分析アプリ\")\n",
        "\n",
        "    # gr.Tabs() で機能を切り替えるタブを作ります\n",
        "    with gr.Tabs():\n",
        "        # 1つ目のタブ\n",
        "        with gr.TabItem(\"画像加工フィルター\"):\n",
        "            gr.Markdown(\"## 好きな画像を加工してみよう！\")\n",
        "            with gr.Row():\n",
        "                # 左側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    image_input_filter = gr.Image(type=\"pil\", label=\"画像をアップロード\")\n",
        "                    process_button = gr.Button(\"加工する！\")\n",
        "                # 右側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    image_output_filter = gr.Image(label=\"加工後の画像\")\n",
        "\n",
        "            # ボタンが押されたら、どの関数を呼び出すか設定\n",
        "            process_button.click(fn=image_filter, inputs=image_input_filter, outputs=image_output_filter)\n",
        "\n",
        "        # 2つ目のタブ\n",
        "        with gr.TabItem(\"AI画像分析\"):\n",
        "            gr.Markdown(\"## AIが写真に写っているものを当てるよ！\")\n",
        "            with gr.Row():\n",
        "                # 左側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    image_input_ai = gr.Image(type=\"pil\", label=\"画像をアップロード\")\n",
        "                    predict_button = gr.Button(\"AIに分析してもらう！\")\n",
        "                # 右側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    # gr.LabelはAIの分析結果を表示するのに便利です\n",
        "                    label_output_ai = gr.Label(num_top_classes=3, label=\"分析結果\")\n",
        "\n",
        "            # ボタンが押されたら、どの関数を呼び出すか設定\n",
        "            predict_button.click(fn=predict_image, inputs=image_input_ai, outputs=label_output_ai)\n",
        "\n",
        "\n",
        "# アプリを起動します\n",
        "print(\"アプリを起動します。URLが表示されたらクリックしてください。\")\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMJ5/vw/GkmYbQtBbiUVFUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
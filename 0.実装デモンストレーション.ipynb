{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuracode/hsprogramming/blob/main/0.%E5%AE%9F%E8%A3%85%E3%83%87%E3%83%A2%E3%83%B3%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUI5hEP6OC7h"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision qrcode gradio -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio, qrcode, Pillow(Image)ã«åŠ ãˆã¦ã€\n",
        "# ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ˆã†ã«æ‰±ã†ãŸã‚ã®`BytesIO`ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
        "import gradio as gr\n",
        "import qrcode\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰QRã‚³ãƒ¼ãƒ‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹`generate_qr`é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
        "def generate_qr(text):\n",
        "    # `qrcode.make()`ã‚’ä½¿ã„ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’QRã‚³ãƒ¼ãƒ‰ã®ç”»åƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚\n",
        "    qr_img = qrcode.make(text)\n",
        "\n",
        "    # --- Colabç­‰ã®ç’°å¢ƒã§ã‚ˆã‚Šå®‰å®šã—ã¦å‹•ä½œã•ã›ã‚‹ãŸã‚ã®å‡¦ç† ---\n",
        "    # `BytesIO`ã‚’ä½¿ã„ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚çš„ã«ä¿å­˜ã™ã‚‹ãŸã‚ã®ãƒ¡ãƒ¢ãƒªé ˜åŸŸ(`buf`)ã‚’ç”¨æ„ã—ã¾ã™ã€‚\n",
        "    buf = BytesIO()\n",
        "    # ç”Ÿæˆã—ãŸQRã‚³ãƒ¼ãƒ‰ç”»åƒã‚’ã€PNGå½¢å¼ã§ãƒ¡ãƒ¢ãƒªé ˜åŸŸ(`buf`)ã«æ›¸ãè¾¼ã¿ã¾ã™ã€‚\n",
        "    qr_img.save(buf, format=\"PNG\")\n",
        "    # æ›¸ãè¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’æœ€åˆã‹ã‚‰èª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†ã«ã€ãƒ¡ãƒ¢ãƒªä¸Šã®ã‚«ãƒ¼ã‚½ãƒ«ã‚’å…ˆé ­ã«æˆ»ã—ã¾ã™ã€‚\n",
        "    buf.seek(0)\n",
        "    # ãƒ¡ãƒ¢ãƒªé ˜åŸŸã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æ”¹ã‚ã¦Pillowã®ç”»åƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦é–‹ãã¾ã™ã€‚\n",
        "    img = Image.open(buf)\n",
        "\n",
        "    # å®‰å…¨ãªå½¢å¼ã«å¤‰æ›ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚\n",
        "    return img\n",
        "\n",
        "# Gradioã®Interfaceã‚’ä½¿ã„ã€Web UIã‚’è¨­è¨ˆã—ã¾ã™ã€‚\n",
        "demo = gr.Interface(fn=generate_qr, inputs=\"text\", outputs=\"image\")\n",
        "\n",
        "# ä½œæˆã—ãŸUIã‚’ã€å¤–éƒ¨ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªå…¬é–‹URLã§èµ·å‹•ã—ã¾ã™ã€‚\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "okZk_LZdHD_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeVSKD2_PDhM"
      },
      "outputs": [],
      "source": [
        "# Gradioãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã€ç”»åƒç”ŸæˆAIã‚’ç°¡å˜ã«æ‰±ã†ãŸã‚ã®`diffusers`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
        "import gradio as gr\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "# stabilityaiãŒæä¾›ã™ã‚‹å­¦ç¿’æ¸ˆã¿ã®ç”»åƒç”ŸæˆAIãƒ¢ãƒ‡ãƒ«ï¼ˆStable Diffusionï¼‰ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
        "# åˆå›å®Ÿè¡Œæ™‚ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\")\n",
        "# èª­ã¿è¾¼ã‚“ã AIãƒ¢ãƒ‡ãƒ«ã‚’GPUã«è»¢é€ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç”»åƒç”ŸæˆãŒé«˜é€Ÿã«ãªã‚Šã¾ã™ã€‚\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®æŒ‡ç¤ºï¼‰ã‚’å—ã‘å–ã‚Šã€ç”»åƒã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
        "def generate_image(prompt):\n",
        "    # AIãƒ¢ãƒ‡ãƒ«(`pipe`)ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã—ã€ç”»åƒç”Ÿæˆã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
        "    # çµæœã®ä¸­ã‹ã‚‰æœ€åˆã®ç”»åƒ(`.images[0]`)ã‚’å–ã‚Šå‡ºã—ã¾ã™ã€‚\n",
        "    image = pipe(prompt).images[0]\n",
        "    # ç”Ÿæˆã•ã‚ŒãŸç”»åƒã‚’è¿”ã—ã¾ã™ã€‚\n",
        "    return image\n",
        "\n",
        "# Gradioã®Interfaceã‚’ä½¿ã„ã€Web UIã‚’è¨­è¨ˆã—ã¾ã™ã€‚\n",
        "demo = gr.Interface(fn=generate_image,\n",
        "                    inputs=\"text\",\n",
        "                    outputs=\"image\",\n",
        "                    # `title=`ã§UIã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã€`description=`ã§èª¬æ˜æ–‡ã‚’è¨­å®šã§ãã¾ã™ã€‚\n",
        "                    title=\"AIã‚¤ãƒ©ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼\",\n",
        "                    description=\"å¥½ããªè¨€è‘‰ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’å…¥åŠ›ã—ã¦ã€ç”»åƒã‚’ä½œã£ã¦ã¿ã‚ˆã†ï¼\")\n",
        "\n",
        "# ä½œæˆã—ãŸUI(`demo`)ã‚’ã€å¤–éƒ¨ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªå…¬é–‹URLã§èµ·å‹•ã—ã¾ã™ã€‚\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72FDbzfyNxmO"
      },
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.models import resnet50\n",
        "import requests\n",
        "\n",
        "# --- AIãƒ¢ãƒ‡ãƒ«ã¨ãƒ©ãƒ™ãƒ«ã®æº–å‚™ ---\n",
        "# ã“ã®æº–å‚™ã¯ä¸€åº¦ã ã‘è¡Œã„ã¾ã™\n",
        "try:\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
        "except Exception as e:\n",
        "    print(f\"AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "    model = None\n",
        "    labels = None\n",
        "\n",
        "# --- 1. ç”»åƒåŠ å·¥ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå‰å›ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰ ---\n",
        "def image_processing(img, filter_type, blur_level, watermark_text):\n",
        "    if img is None:\n",
        "        return None, \"ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\"\n",
        "    processed_img = img.copy()\n",
        "    if filter_type == \"ç™½é»’\":\n",
        "        processed_img = processed_img.convert('L')\n",
        "    elif filter_type == \"90åº¦å›è»¢\":\n",
        "        processed_img = processed_img.rotate(90, expand=True)\n",
        "    if blur_level > 0:\n",
        "        processed_img = processed_img.filter(ImageFilter.GaussianBlur(radius=blur_level))\n",
        "    if watermark_text:\n",
        "        draw = ImageDraw.Draw(processed_img)\n",
        "        draw.text((10, 10), watermark_text, fill=\"white\", stroke_width=1, stroke_fill=\"black\")\n",
        "    return processed_img, f\"å‡¦ç†å®Œäº†ï¼š{filter_type}\"\n",
        "\n",
        "# --- 2. AIã«ã‚ˆã‚‹ç”»åƒåˆ†æã®ãƒ­ã‚¸ãƒƒã‚¯ ---\n",
        "# (æ•™æã®ã‚³ãƒ¼ãƒ‰ã‚’é–¢æ•°ã¨ã—ã¦æ•´ç†)\n",
        "@torch.no_grad()\n",
        "def predict(input_img):\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ã‹ã€ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚\"\n",
        "\n",
        "    # PIL Imageã‚’PyTorchãŒæ‰±ãˆã‚‹Tensorã«å¤‰æ›\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # ç™½é»’ç”»åƒã®å ´åˆ\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    # æ¨è«–ã®å®Ÿè¡Œ\n",
        "    output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    # çµæœã‚’{ãƒ©ãƒ™ãƒ«: ç¢ºç‡}ã®è¾æ›¸å½¢å¼ã§è¿”ã™\n",
        "    return {labels[i]: float(probs[i]) for i in range(1000)}\n",
        "\n",
        "# --- Gradioã®UIã‚’æ§‹ç¯‰ ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ç·åˆç”»åƒå‡¦ç†ã‚¢ãƒ—ãƒª\")\n",
        "    gr.Markdown(\"æ‰‹å‹•ã§ã®ç”»åƒåŠ å·¥ã¨ã€AIã«ã‚ˆã‚‹ç”»åƒåˆ†æãŒã§ãã¾ã™ã€‚\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- ã‚¿ãƒ–1: ç”»åƒåŠ å·¥ ---\n",
        "        with gr.TabItem(\"ç”»åƒåŠ å·¥\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    proc_input = gr.Image(type=\"pil\", label=\"åŠ å·¥ã—ãŸã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "                    filter_radio = gr.Radio([\"ãªã—\", \"ç™½é»’\", \"90åº¦å›è»¢\"], label=\"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é¸æŠ\", value=\"ãªã—\")\n",
        "                    blur_slider = gr.Slider(0, 10, value=0, label=\"ã¼ã‹ã—ã®å¼·ã•\")\n",
        "                    watermark_input = gr.Textbox(label=\"é€ã‹ã—æ–‡å­—\")\n",
        "                    proc_btn = gr.Button(\"ç”»åƒå‡¦ç†ã‚’å®Ÿè¡Œ\")\n",
        "                with gr.Column():\n",
        "                    proc_output = gr.Image(label=\"åŠ å·¥å¾Œã®ç”»åƒ\")\n",
        "                    proc_status = gr.Textbox(label=\"å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹\")\n",
        "            proc_btn.click(\n",
        "                fn=image_processing,\n",
        "                inputs=[proc_input, filter_radio, blur_slider, watermark_input],\n",
        "                outputs=[proc_output, proc_status]\n",
        "            )\n",
        "\n",
        "        # --- ã‚¿ãƒ–2: AIç”»åƒåˆ†æ ---\n",
        "        with gr.TabItem(\"AIç”»åƒåˆ†æ\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ai_input = gr.Image(type=\"pil\", label=\"åˆ†æã—ãŸã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "                    ai_btn = gr.Button(\"AIåˆ†æã‚’å®Ÿè¡Œ\")\n",
        "                with gr.Column():\n",
        "                    ai_output = gr.Label(num_top_classes=5, label=\"åˆ†æçµæœ\")\n",
        "            ai_btn.click(\n",
        "                fn=predict,\n",
        "                inputs=ai_input,\n",
        "                outputs=ai_output\n",
        "            )\n",
        "\n",
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ä¿ƒã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
        "print(\"\\nã‚‚ã— 'torch' ã‚„ 'torchvision' ãŒãªã„ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ã€!pip install torch torchvision ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c2mNwwx7SyNu"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# 2ã‚³ãƒç›®ãƒ»æ”¹ï¼šAIã®æ€è€ƒã‚’è¦—ãï¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰©ä½“èªè­˜\n",
        "# ================================================================\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—1ï¼†2ï¼šæº–å‚™ï¼ˆåˆå›ã¨åŒã˜ï¼‰\n",
        "# ----------------------------------------------------------------\n",
        "!pip install transformers torch gradio --quiet\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—3ï¼šAIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã¨åŒã˜ï¼‰\n",
        "# ----------------------------------------------------------------\n",
        "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—4ï¼šAIã®ã€Œæ€è€ƒã€ã‚’å¯è¦–åŒ–ã™ã‚‹ã€Œå‘½ä»¤ã€ã‚’ä½œã‚‹\n",
        "# ----------------------------------------------------------------\n",
        "# äºˆæ¸¬çµæœã®ãƒªã‚¹ãƒˆã‚’ã€Gradioã®Labelã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒæ‰±ãˆã‚‹å½¢å¼ï¼ˆè¾æ›¸ï¼‰ã«å¤‰æ›ã™ã‚‹\n",
        "# ----------------------------------------------------------------\n",
        "def classify_image_realtime(image):\n",
        "    # ç”»åƒãŒå…¥åŠ›ã•ã‚Œã¦ã„ãªã„å ´åˆã¯Noneã‚’è¿”ã™\n",
        "    if image is None:\n",
        "        return None\n",
        "\n",
        "    predictions = image_classifier(image)\n",
        "\n",
        "    # äºˆæ¸¬çµæœã‚’ {ãƒ©ãƒ™ãƒ«å: ç¢ºä¿¡åº¦ã‚¹ã‚³ã‚¢} ã®è¾æ›¸å½¢å¼ã«å¤‰æ›ã™ã‚‹\n",
        "    # ä¸Šä½3ä»¶ã ã‘ã‚’å–ã‚Šå‡ºã™\n",
        "    result_dict = {p['label']: p['score'] for p in predictions[:10]}\n",
        "    return result_dict\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ã‚¹ãƒ†ãƒƒãƒ—5ï¼šãƒ©ã‚¤ãƒ–ã‚«ãƒ¡ãƒ©å¯¾å¿œã®æ“ä½œãƒ‘ãƒãƒ«ã‚’èµ·å‹•ã™ã‚‹\n",
        "# ----------------------------------------------------------------\n",
        "# inputsã«Webã‚«ãƒ¡ãƒ©ã‚’æŒ‡å®šã—ã€live=True ã«è¨­å®šã™ã‚‹ã“ã¨ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ãŒå®Ÿç¾ã™ã‚‹\n",
        "# ----------------------------------------------------------------\n",
        "gr.Interface(fn=classify_image_realtime,\n",
        "             inputs=gr.Image(sources=[\"webcam\"], type=\"pil\", label=\"Webã‚«ãƒ¡ãƒ©\"),\n",
        "             outputs=gr.Label(num_top_classes=10, label=\"AIã®èªè­˜çµæœï¼ˆãƒˆãƒƒãƒ—10ï¼‰\"),\n",
        "             title=\"ğŸ‘€ AIã®æ€è€ƒã‚’è¦—ãï¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰©ä½“èªè­˜ã‚«ãƒ¡ãƒ©\",\n",
        "             description=\"Webã‚«ãƒ¡ãƒ©ã«èº«ã®å›ã‚Šã®ã‚‚ã®ã‚’å†™ã—ã¦ã¿ã¦ãã ã•ã„ã€‚AIãŒä½•ã‚’èªè­˜ã—ã¦ã„ã‚‹ã‹ã€ãã®ç¢ºä¿¡åº¦ã¨ä¸€ç·’ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã—ã¾ã™ã€‚\",\n",
        "             live=True).launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG6JpuoiMzXS"
      },
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.models import resnet50\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "# --- AIãƒ¢ãƒ‡ãƒ«ã¨ãƒ©ãƒ™ãƒ«ã®æº–å‚™ ---\n",
        "# ã“ã®æº–å‚™ã¯ä¸€åº¦ã ã‘è¡Œã„ã¾ã™\n",
        "try:\n",
        "    # Image Classification model\n",
        "    image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "    # ResNet50 for image analysis\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
        "except Exception as e:\n",
        "    print(f\"AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
        "    image_classifier = None\n",
        "    model = None\n",
        "    labels = None\n",
        "\n",
        "# --- 1. ç”»åƒåŠ å·¥ã®ãƒ­ã‚¸ãƒƒã‚¯ ---\n",
        "def image_processing(img, filter_type, blur_level, watermark_text):\n",
        "    if img is None:\n",
        "        return None, \"ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\"\n",
        "    processed_img = img.copy()\n",
        "    if filter_type == \"ç™½é»’\":\n",
        "        processed_img = processed_img.convert('L')\n",
        "    elif filter_type == \"90åº¦å›è»¢\":\n",
        "        processed_img = processed_img.rotate(90, expand=True)\n",
        "    if blur_level > 0:\n",
        "        processed_img = processed_img.filter(ImageFilter.GaussianBlur(radius=blur_level))\n",
        "    if watermark_text:\n",
        "        draw = ImageDraw.Draw(processed_img)\n",
        "        draw.text((10, 10), watermark_text, fill=\"white\", stroke_width=1, stroke_fill=\"black\")\n",
        "    return processed_img, f\"å‡¦ç†å®Œäº†ï¼š{filter_type}\"\n",
        "\n",
        "# --- 2. AIã«ã‚ˆã‚‹ç”»åƒåˆ†æã®ãƒ­ã‚¸ãƒƒã‚¯ ---\n",
        "@torch.no_grad()\n",
        "def predict(input_img):\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ã‹ã€ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚\"\n",
        "\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # ç™½é»’ç”»åƒã®å ´åˆ\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    return {labels[i]: float(probs[i]) for i in range(1000)}\n",
        "\n",
        "# --- 3. AIã®ã€Œæ€è€ƒã€ã‚’å¯è¦–åŒ–ã™ã‚‹ã€Œå‘½ä»¤ã€ã‚’ä½œã‚‹ (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰©ä½“èªè­˜) ---\n",
        "def classify_image_realtime(image):\n",
        "    if image_classifier is None or image is None:\n",
        "        return \"AIãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ã‹ã€ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚\"\n",
        "\n",
        "    predictions = image_classifier(image)\n",
        "\n",
        "    result_dict = {p['label']: p['score'] for p in predictions[:10]}\n",
        "    return result_dict\n",
        "\n",
        "# --- Gradioã®UIã‚’æ§‹ç¯‰ ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ç·åˆç”»åƒå‡¦ç†ã‚¢ãƒ—ãƒª\")\n",
        "    gr.Markdown(\"æ‰‹å‹•ã§ã®ç”»åƒåŠ å·¥ã€AIã«ã‚ˆã‚‹ç”»åƒåˆ†æã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰©ä½“èªè­˜ãŒã§ãã¾ã™ã€‚\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- ã‚¿ãƒ–1: ç”»åƒåŠ å·¥ ---\n",
        "        with gr.TabItem(\"ç”»åƒåŠ å·¥\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    proc_input = gr.Image(type=\"pil\", label=\"åŠ å·¥ã—ãŸã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "                    filter_radio = gr.Radio([\"ãªã—\", \"ç™½é»’\", \"90åº¦å›è»¢\"], label=\"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é¸æŠ\", value=\"ãªã—\")\n",
        "                    blur_slider = gr.Slider(0, 10, value=0, label=\"ã¼ã‹ã—ã®å¼·ã•\")\n",
        "                    watermark_input = gr.Textbox(label=\"é€ã‹ã—æ–‡å­—\")\n",
        "                    proc_btn = gr.Button(\"ç”»åƒå‡¦ç†ã‚’å®Ÿè¡Œ\")\n",
        "                with gr.Column():\n",
        "                    proc_output = gr.Image(label=\"åŠ å·¥å¾Œã®ç”»åƒ\")\n",
        "                    proc_status = gr.Textbox(label=\"å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹\")\n",
        "            proc_btn.click(\n",
        "                fn=image_processing,\n",
        "                inputs=[proc_input, filter_radio, blur_slider, watermark_input],\n",
        "                outputs=[proc_output, proc_status]\n",
        "            )\n",
        "\n",
        "        # --- ã‚¿ãƒ–2: AIç”»åƒåˆ†æ ---\n",
        "        with gr.TabItem(\"AIç”»åƒåˆ†æ\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ai_input = gr.Image(type=\"pil\", label=\"åˆ†æã—ãŸã„ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "                    ai_btn = gr.Button(\"AIåˆ†æã‚’å®Ÿè¡Œ\")\n",
        "                with gr.Column():\n",
        "                    ai_output = gr.Label(num_top_classes=5, label=\"åˆ†æçµæœ\")\n",
        "            ai_btn.click(\n",
        "                fn=predict,\n",
        "                inputs=ai_input,\n",
        "                outputs=ai_output\n",
        "            )\n",
        "\n",
        "        # --- ã‚¿ãƒ–3: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰©ä½“èªè­˜ ---\n",
        "        with gr.TabItem(\"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰©ä½“èªè­˜\"):\n",
        "             with gr.Row():\n",
        "                 with gr.Column():\n",
        "                     realtime_input = gr.Image(sources=[\"webcam\"], type=\"pil\", label=\"Webã‚«ãƒ¡ãƒ©\")\n",
        "                     # realtime_btn = gr.Button(\"AIåˆ†æã‚’å®Ÿè¡Œ (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ )\") # ãƒœã‚¿ãƒ³ã¯ä¸è¦ãªã®ã§å‰Šé™¤\n",
        "                 with gr.Column():\n",
        "                     realtime_output = gr.Label(num_top_classes=10, label=\"AIã®èªè­˜çµæœï¼ˆãƒˆãƒƒãƒ—10ï¼‰\")\n",
        "             # Use change() for real-time updates from webcam\n",
        "             realtime_input.change(\n",
        "                 fn=classify_image_realtime,\n",
        "                 inputs=realtime_input,\n",
        "                 outputs=realtime_output,\n",
        "                 live=True # Add live=True for real-time updates\n",
        "             )\n",
        "\n",
        "\n",
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ä¿ƒã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸\n",
        "print(\"\\nã‚‚ã— 'torch' ã‚„ 'torchvision' ãŒãªã„ã¨ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ã€!pip install torch torchvision ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
        "# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p99xOJu6BCe8"
      },
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™\n",
        "# gradio: Web UIã‚’ç°¡å˜ã«ä½œã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "# PIL (Pillow): ç”»åƒã‚’åŠ å·¥ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "# numpy: æ•°å€¤è¨ˆç®—ã€ç‰¹ã«AIã§ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "# ãã®ä»–: AIãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã™ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "# --- ã“ã“ã‹ã‚‰AIã®æº–å‚™ (ã“ã®éƒ¨åˆ†ã¯å®Œæˆã—ã¦ã„ã¾ã™) ---\n",
        "# æˆæ¥­ã§ä½¿ã£ãŸResNet50ãƒ¢ãƒ‡ãƒ«ã¨ImageNetãƒ©ãƒ™ãƒ«ã‚’æº–å‚™ã—ã¾ã™\n",
        "# ã“ã®éƒ¨åˆ†ã¯ä¸€åº¦ã ã‘å®Ÿè¡Œã•ã‚Œã¾ã™\n",
        "try:\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™OKï¼\")\n",
        "except Exception as e:\n",
        "    print(\"AIãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\", e)\n",
        "    model = None\n",
        "    labels = None\n",
        "# --- AIã®æº–å‚™ã“ã“ã¾ã§ ---\n",
        "\n",
        "\n",
        "# --- é–¢æ•°ã‚’å®šç¾©ã™ã‚‹ã‚¨ãƒªã‚¢ ---\n",
        "\n",
        "# ã€èª²é¡Œï¼‘ã€‘ç”»åƒåŠ å·¥ç”¨ã®é–¢æ•°ã‚’å®Œæˆã•ã›ã‚ˆã†ï¼\n",
        "# 1ã‚³ãƒç›®ã®æœ€å¾Œã«ä½œã£ãŸã€Œç™½é»’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ã®å‡¦ç†ã‚’æ€ã„å‡ºã—ã¦æ›¸ã„ã¦ã¿ã‚ˆã†ï¼\n",
        "def image_filter(input_img):\n",
        "    print(\"ç”»åƒåŠ å·¥ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸï¼\")\n",
        "    if input_img is None:\n",
        "        return None # ç”»åƒãŒãªã‘ã‚Œã°ä½•ã‚‚ã—ãªã„\n",
        "\n",
        "    # â–¼â–¼â–¼ ã“ã“ã«ã€Pillowã‚’ä½¿ã£ãŸç”»åƒå‡¦ç†ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã‚ˆã† â–¼â–¼â–¼\n",
        "    # ãƒ’ãƒ³ãƒˆ: input_img.convert('L') ã‚’ä½¿ã†ã¨ç™½é»’ã«ã§ãã¾ã™\n",
        "\n",
        "    processed_img = input_img.convert('L') # ä»Šã¯ã¾ã ä½•ã‚‚ã—ãªã„ã®ã§ã€ã“ã®è¡Œã‚’æ›¸ãæ›ãˆã‚ˆã†ï¼\n",
        "\n",
        "    # â–²â–²â–² ã“ã“ã¾ã§ â–²â–²â–²\n",
        "\n",
        "    return processed_img\n",
        "\n",
        "\n",
        "# ã€èª²é¡Œï¼’ã€‘AIåˆ†æç”¨ã®é–¢æ•°ã‚’å®Œæˆã•ã›ã‚ˆã†ï¼\n",
        "# 2ã‚³ãƒç›®ã«ä½“é¨“ã—ãŸã€ŒAIã«ã‚ˆã‚‹ç”»åƒåˆ¤å®šã€ã®ã‚³ãƒ¼ãƒ‰ã‚’å‚è€ƒã«ã€ä¸­èº«ã‚’å®Œæˆã•ã›ã‚ˆã†ï¼\n",
        "def predict_image(input_img):\n",
        "    print(\"AIåˆ†æãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸï¼\")\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™ã§ãã¦ã„ãªã„ã‹ã€ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚\"\n",
        "\n",
        "    # â–¼â–¼â–¼ ã“ã“ã«ã€AIã«ç”»åƒã‚’åˆ†æã•ã›ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã‚ˆã† â–¼â–¼â–¼\n",
        "    # ãƒ’ãƒ³ãƒˆ: æ•™æã€3.Gradio(Webã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹)ã®åŸºæœ¬.ipynbã€ã®æœ€å¾Œã®éƒ¨åˆ†ã‚’å‚è€ƒã«ã—ã‚ˆã†\n",
        "    # æ‰‹é †ï¼‘ï¼šç”»åƒã®å‰å‡¦ç† (ãƒªã‚µã‚¤ã‚ºã€Tensorã«å¤‰æ›ã€æ­£è¦åŒ–)\n",
        "    # æ‰‹é †ï¼’ï¼šAIã«ã‚ˆã‚‹æ¨è«– (model(img) ã‚’å‘¼ã³å‡ºã™)\n",
        "    # æ‰‹é †ï¼“ï¼šçµæœã‚’æ•´å½¢ã—ã¦ã€returnã§è¿”ã™\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # ç™½é»’ç”»åƒã®å ´åˆ\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    # æ¨è«–ã®å®Ÿè¡Œ\n",
        "    with torch.no_grad():\n",
        "        output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    # çµæœã‚’{ãƒ©ãƒ™ãƒ«: ç¢ºç‡}ã®è¾æ›¸å½¢å¼ã§è¿”ã™\n",
        "    result = {labels[i]: float(probs[i]) for i in range(1000)} # ä»Šã¯ã¾ã ãƒ€ãƒŸãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€ã“ã®è¡Œã‚’æ›¸ãæ›ãˆã‚ˆã†ï¼\n",
        "\n",
        "    # â–²â–²â–² ã“ã“ã¾ã§ â–²â–²â–²\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- Web UIã‚’ä½œã‚‹ã‚¨ãƒªã‚¢ (ã“ã®éƒ¨åˆ†ã¯å®Œæˆã—ã¦ã„ã¾ã™) ---\n",
        "# gr.Blocks() ã‚’ä½¿ã†ã¨ã€ã‚ˆã‚Šè‡ªç”±ã«UIã‚’çµ„ã¿ç«‹ã¦ã‚‰ã‚Œã¾ã™\n",
        "with gr.Blocks() as demo:\n",
        "    # ã‚¢ãƒ—ãƒªå…¨ä½“ã®ã‚¿ã‚¤ãƒˆãƒ«\n",
        "    gr.Markdown(\"# ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒåŠ å·¥ï¼†AIåˆ†æã‚¢ãƒ—ãƒª\")\n",
        "\n",
        "    # gr.Tabs() ã§æ©Ÿèƒ½ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚¿ãƒ–ã‚’ä½œã‚Šã¾ã™\n",
        "    with gr.Tabs():\n",
        "        # 1ã¤ç›®ã®ã‚¿ãƒ–\n",
        "        with gr.TabItem(\"ç”»åƒåŠ å·¥ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼\"):\n",
        "            gr.Markdown(\"## å¥½ããªç”»åƒã‚’åŠ å·¥ã—ã¦ã¿ã‚ˆã†ï¼\")\n",
        "            with gr.Row():\n",
        "                # å·¦å´ã«é…ç½®ã™ã‚‹UIéƒ¨å“\n",
        "                with gr.Column():\n",
        "                    image_input_filter = gr.Image(type=\"pil\", label=\"ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "                    process_button = gr.Button(\"åŠ å·¥ã™ã‚‹ï¼\")\n",
        "                # å³å´ã«é…ç½®ã™ã‚‹UIéƒ¨å“\n",
        "                with gr.Column():\n",
        "                    image_output_filter = gr.Image(label=\"åŠ å·¥å¾Œã®ç”»åƒ\")\n",
        "\n",
        "            # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ã€ã©ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™ã‹è¨­å®š\n",
        "            process_button.click(fn=image_filter, inputs=image_input_filter, outputs=image_output_filter)\n",
        "\n",
        "        # 2ã¤ç›®ã®ã‚¿ãƒ–\n",
        "        with gr.TabItem(\"AIç”»åƒåˆ†æ\"):\n",
        "            gr.Markdown(\"## AIãŒå†™çœŸã«å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã‚’å½“ã¦ã‚‹ã‚ˆï¼\")\n",
        "            with gr.Row():\n",
        "                # å·¦å´ã«é…ç½®ã™ã‚‹UIéƒ¨å“\n",
        "                with gr.Column():\n",
        "                    image_input_ai = gr.Image(type=\"pil\", label=\"ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\")\n",
        "                    predict_button = gr.Button(\"AIã«åˆ†æã—ã¦ã‚‚ã‚‰ã†ï¼\")\n",
        "                # å³å´ã«é…ç½®ã™ã‚‹UIéƒ¨å“\n",
        "                with gr.Column():\n",
        "                    # gr.Labelã¯AIã®åˆ†æçµæœã‚’è¡¨ç¤ºã™ã‚‹ã®ã«ä¾¿åˆ©ã§ã™\n",
        "                    label_output_ai = gr.Label(num_top_classes=3, label=\"åˆ†æçµæœ\")\n",
        "\n",
        "            # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ã€ã©ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™ã‹è¨­å®š\n",
        "            predict_button.click(fn=predict_image, inputs=image_input_ai, outputs=label_output_ai)\n",
        "\n",
        "\n",
        "# ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™\n",
        "print(\"ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™ã€‚URLãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚\")\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMJ5/vw/GkmYbQtBbiUVFUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
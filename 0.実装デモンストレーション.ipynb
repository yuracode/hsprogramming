{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuracode/hsprogramming/blob/main/0.%E5%AE%9F%E8%A3%85%E3%83%87%E3%83%A2%E3%83%B3%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUI5hEP6OC7h"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "9d4b320ad848455b9d3abe8bf571f28e",
            "1f6d5fe4efcb47688c1c27b6976482b8",
            "9576e8548b364f0eae4d3999e71fff9e",
            "61b2481195be47ec81b10b9276b590c1",
            "f71b07299b324fd8bd9e97e7cccd6c73",
            "c8299b142a7648c1905e33fafa213b76",
            "4e71857b892448389e9aabf3c0554bda",
            "187cea5f0a3142e89c7d9e54eac727fc",
            "67754df303e34b69b69e12042dc99a4d",
            "0e8aba57a04844c8af614b7a51091c01",
            "c976e311e30b428587e7e2d79e208f9a",
            "9baf03f14533451cbb568214cdf622d6",
            "4635b75ca90e4e529773ce419da5c217",
            "f2d81490f3cf4d59be658ebe86ebbc24",
            "148007a9fa9546dab928a2cc45526812"
          ]
        },
        "id": "OeVSKD2_PDhM",
        "outputId": "9e59ab52-79e6-4df1-f079-af989cf0ad37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d4b320ad848455b9d3abe8bf571f28e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/543 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f6d5fe4efcb47688c1c27b6976482b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9576e8548b364f0eae4d3999e71fff9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61b2481195be47ec81b10b9276b590c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f71b07299b324fd8bd9e97e7cccd6c73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/346 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8299b142a7648c1905e33fafa213b76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e71857b892448389e9aabf3c0554bda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "187cea5f0a3142e89c7d9e54eac727fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67754df303e34b69b69e12042dc99a4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "text_encoder/model.safetensors:   0%|          | 0.00/1.36G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e8aba57a04844c8af614b7a51091c01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c976e311e30b428587e7e2d79e208f9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9baf03f14533451cbb568214cdf622d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/911 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4635b75ca90e4e529773ce419da5c217",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2d81490f3cf4d59be658ebe86ebbc24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "148007a9fa9546dab928a2cc45526812",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fe0d1742b18c821328.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fe0d1742b18c821328.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "# モデルの読み込み（初回は時間がかかります）\n",
        "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\")\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "def generate_image(prompt):\n",
        "    image = pipe(prompt).images[0]\n",
        "    return image\n",
        "\n",
        "# Gradioインターフェースの作成\n",
        "iface = gr.Interface(fn=generate_image,\n",
        "                     inputs=\"text\",\n",
        "                     outputs=\"image\",\n",
        "                     title=\"AIイラストレーター\",\n",
        "                     description=\"好きな言葉（プロンプト）を入力して、画像を作ってみよう！\")\n",
        "iface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "72FDbzfyNxmO",
        "outputId": "a3b4b4b8-4aa0-4f2e-9df5-8f7f8859e7ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 165MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIモデルの準備が完了しました。\n",
            "\n",
            "もし 'torch' や 'torchvision' がないというエラーが出たら、!pip install torch torchvision を実行してください。\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d6a60249bebf9bbee9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d6a60249bebf9bbee9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 必要なライブラリをすべてインポート\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.models import resnet50\n",
        "import requests\n",
        "\n",
        "# --- AIモデルとラベルの準備 ---\n",
        "# この準備は一度だけ行います\n",
        "try:\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIモデルの準備が完了しました。\")\n",
        "except Exception as e:\n",
        "    print(f\"AIモデルの準備中にエラーが発生しました: {e}\")\n",
        "    model = None\n",
        "    labels = None\n",
        "\n",
        "# --- 1. 画像加工のロジック（前回のコードと同じ） ---\n",
        "def image_processing(img, filter_type, blur_level, watermark_text):\n",
        "    if img is None:\n",
        "        return None, \"画像をアップロードしてください。\"\n",
        "    processed_img = img.copy()\n",
        "    if filter_type == \"白黒\":\n",
        "        processed_img = processed_img.convert('L')\n",
        "    elif filter_type == \"90度回転\":\n",
        "        processed_img = processed_img.rotate(90, expand=True)\n",
        "    if blur_level > 0:\n",
        "        processed_img = processed_img.filter(ImageFilter.GaussianBlur(radius=blur_level))\n",
        "    if watermark_text:\n",
        "        draw = ImageDraw.Draw(processed_img)\n",
        "        draw.text((10, 10), watermark_text, fill=\"white\", stroke_width=1, stroke_fill=\"black\")\n",
        "    return processed_img, f\"処理完了：{filter_type}\"\n",
        "\n",
        "# --- 2. AIによる画像分析のロジック ---\n",
        "# (教材のコードを関数として整理)\n",
        "@torch.no_grad()\n",
        "def predict(input_img):\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    # PIL ImageをPyTorchが扱えるTensorに変換\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # 白黒画像の場合\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    # 推論の実行\n",
        "    output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    # 結果を{ラベル: 確率}の辞書形式で返す\n",
        "    return {labels[i]: float(probs[i]) for i in range(1000)}\n",
        "\n",
        "# --- GradioのUIを構築 ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 総合画像処理アプリ\")\n",
        "    gr.Markdown(\"手動での画像加工と、AIによる画像分析ができます。\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- タブ1: 画像加工 ---\n",
        "        with gr.TabItem(\"画像加工\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    proc_input = gr.Image(type=\"pil\", label=\"加工したい画像をアップロード\")\n",
        "                    filter_radio = gr.Radio([\"なし\", \"白黒\", \"90度回転\"], label=\"フィルターを選択\", value=\"なし\")\n",
        "                    blur_slider = gr.Slider(0, 10, value=0, label=\"ぼかしの強さ\")\n",
        "                    watermark_input = gr.Textbox(label=\"透かし文字\")\n",
        "                    proc_btn = gr.Button(\"画像処理を実行\")\n",
        "                with gr.Column():\n",
        "                    proc_output = gr.Image(label=\"加工後の画像\")\n",
        "                    proc_status = gr.Textbox(label=\"処理ステータス\")\n",
        "            proc_btn.click(\n",
        "                fn=image_processing,\n",
        "                inputs=[proc_input, filter_radio, blur_slider, watermark_input],\n",
        "                outputs=[proc_output, proc_status]\n",
        "            )\n",
        "\n",
        "        # --- タブ2: AI画像分析 ---\n",
        "        with gr.TabItem(\"AI画像分析\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ai_input = gr.Image(type=\"pil\", label=\"分析したい画像をアップロード\")\n",
        "                    ai_btn = gr.Button(\"AI分析を実行\")\n",
        "                with gr.Column():\n",
        "                    ai_output = gr.Label(num_top_classes=5, label=\"分析結果\")\n",
        "            ai_btn.click(\n",
        "                fn=predict,\n",
        "                inputs=ai_input,\n",
        "                outputs=ai_output\n",
        "            )\n",
        "\n",
        "# 必要なライブラリのインストールを促すメッセージ\n",
        "print(\"\\nもし 'torch' や 'torchvision' がないというエラーが出たら、!pip install torch torchvision を実行してください。\")\n",
        "# アプリケーションの起動\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "ded07c0629f44935bbac07495789bba6",
            "b259c5afd61c482da7676e279df0f587",
            "4d5664d6ca874b48a58527adf8e30bf8"
          ]
        },
        "id": "c2mNwwx7SyNu",
        "outputId": "e1085094-5f86-4be2-fa8b-fd8e6ad9f018"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ded07c0629f44935bbac07495789bba6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b259c5afd61c482da7676e279df0f587",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d5664d6ca874b48a58527adf8e30bf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7ea9aed341af83350e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://7ea9aed341af83350e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 2コマ目・改：AIの思考を覗く！リアルタイム物体認識\n",
        "# ================================================================\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ1＆2：準備（初回と同じ）\n",
        "# ----------------------------------------------------------------\n",
        "!pip install transformers torch gradio --quiet\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ3：AIモデルの読み込み（初回と同じ）\n",
        "# ----------------------------------------------------------------\n",
        "image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ4：AIの「思考」を可視化する「命令」を作る\n",
        "# ----------------------------------------------------------------\n",
        "# 予測結果のリストを、GradioのLabelコンポーネントが扱える形式（辞書）に変換する\n",
        "# ----------------------------------------------------------------\n",
        "def classify_image_realtime(image):\n",
        "    # 画像が入力されていない場合はNoneを返す\n",
        "    if image is None:\n",
        "        return None\n",
        "\n",
        "    predictions = image_classifier(image)\n",
        "\n",
        "    # 予測結果を {ラベル名: 確信度スコア} の辞書形式に変換する\n",
        "    # 上位3件だけを取り出す\n",
        "    result_dict = {p['label']: p['score'] for p in predictions[:10]}\n",
        "    return result_dict\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# ステップ5：ライブカメラ対応の操作パネルを起動する\n",
        "# ----------------------------------------------------------------\n",
        "# inputsにWebカメラを指定し、live=True に設定することでリアルタイム処理が実現する\n",
        "# ----------------------------------------------------------------\n",
        "gr.Interface(fn=classify_image_realtime,\n",
        "             inputs=gr.Image(sources=[\"webcam\"], type=\"pil\", label=\"Webカメラ\"),\n",
        "             outputs=gr.Label(num_top_classes=10, label=\"AIの認識結果（トップ10）\"),\n",
        "             title=\"👀 AIの思考を覗く！リアルタイム物体認識カメラ\",\n",
        "             description=\"Webカメラに身の回りのものを写してみてください。AIが何を認識しているか、その確信度と一緒にリアルタイムで表示します。\",\n",
        "             live=True).launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wG6JpuoiMzXS",
        "outputId": "658ccc1b-ce7e-4f76-a782-c8ba76f4e710"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIモデルの準備が完了しました。\n",
            "\n",
            "もし 'torch' や 'torchvision' がないというエラーが出たら、!pip install torch torchvision を実行してください。\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://72b6a96381540bf61a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://72b6a96381540bf61a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 必要なライブラリをすべてインポート\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.models import resnet50\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "# --- AIモデルとラベルの準備 ---\n",
        "# この準備は一度だけ行います\n",
        "try:\n",
        "    # Image Classification model\n",
        "    image_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
        "    # ResNet50 for image analysis\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIモデルの準備が完了しました。\")\n",
        "except Exception as e:\n",
        "    print(f\"AIモデルの準備中にエラーが発生しました: {e}\")\n",
        "    image_classifier = None\n",
        "    model = None\n",
        "    labels = None\n",
        "\n",
        "# --- 1. 画像加工のロジック ---\n",
        "def image_processing(img, filter_type, blur_level, watermark_text):\n",
        "    if img is None:\n",
        "        return None, \"画像をアップロードしてください。\"\n",
        "    processed_img = img.copy()\n",
        "    if filter_type == \"白黒\":\n",
        "        processed_img = processed_img.convert('L')\n",
        "    elif filter_type == \"90度回転\":\n",
        "        processed_img = processed_img.rotate(90, expand=True)\n",
        "    if blur_level > 0:\n",
        "        processed_img = processed_img.filter(ImageFilter.GaussianBlur(radius=blur_level))\n",
        "    if watermark_text:\n",
        "        draw = ImageDraw.Draw(processed_img)\n",
        "        draw.text((10, 10), watermark_text, fill=\"white\", stroke_width=1, stroke_fill=\"black\")\n",
        "    return processed_img, f\"処理完了：{filter_type}\"\n",
        "\n",
        "# --- 2. AIによる画像分析のロジック ---\n",
        "@torch.no_grad()\n",
        "def predict(input_img):\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # 白黒画像の場合\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    return {labels[i]: float(probs[i]) for i in range(1000)}\n",
        "\n",
        "# --- 3. AIの「思考」を可視化する「命令」を作る (リアルタイム物体認識) ---\n",
        "def classify_image_realtime(image):\n",
        "    if image_classifier is None or image is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    predictions = image_classifier(image)\n",
        "\n",
        "    result_dict = {p['label']: p['score'] for p in predictions[:10]}\n",
        "    return result_dict\n",
        "\n",
        "# --- GradioのUIを構築 ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# 総合画像処理アプリ\")\n",
        "    gr.Markdown(\"手動での画像加工、AIによる画像分析、リアルタイム物体認識ができます。\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        # --- タブ1: 画像加工 ---\n",
        "        with gr.TabItem(\"画像加工\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    proc_input = gr.Image(type=\"pil\", label=\"加工したい画像をアップロード\")\n",
        "                    filter_radio = gr.Radio([\"なし\", \"白黒\", \"90度回転\"], label=\"フィルターを選択\", value=\"なし\")\n",
        "                    blur_slider = gr.Slider(0, 10, value=0, label=\"ぼかしの強さ\")\n",
        "                    watermark_input = gr.Textbox(label=\"透かし文字\")\n",
        "                    proc_btn = gr.Button(\"画像処理を実行\")\n",
        "                with gr.Column():\n",
        "                    proc_output = gr.Image(label=\"加工後の画像\")\n",
        "                    proc_status = gr.Textbox(label=\"処理ステータス\")\n",
        "            proc_btn.click(\n",
        "                fn=image_processing,\n",
        "                inputs=[proc_input, filter_radio, blur_slider, watermark_input],\n",
        "                outputs=[proc_output, proc_status]\n",
        "            )\n",
        "\n",
        "        # --- タブ2: AI画像分析 ---\n",
        "        with gr.TabItem(\"AI画像分析\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    ai_input = gr.Image(type=\"pil\", label=\"分析したい画像をアップロード\")\n",
        "                    ai_btn = gr.Button(\"AI分析を実行\")\n",
        "                with gr.Column():\n",
        "                    ai_output = gr.Label(num_top_classes=5, label=\"分析結果\")\n",
        "            ai_btn.click(\n",
        "                fn=predict,\n",
        "                inputs=ai_input,\n",
        "                outputs=ai_output\n",
        "            )\n",
        "\n",
        "        # --- タブ3: リアルタイム物体認識 ---\n",
        "        with gr.TabItem(\"リアルタイム物体認識\"):\n",
        "             with gr.Row():\n",
        "                 with gr.Column():\n",
        "                     realtime_input = gr.Image(sources=[\"webcam\"], type=\"pil\", label=\"Webカメラ\")\n",
        "                     realtime_btn = gr.Button(\"AI分析を実行 (リアルタイム)\") # ボタンは不要だが、UIを合わせるために残す\n",
        "                 with gr.Column():\n",
        "                     realtime_output = gr.Label(num_top_classes=10, label=\"AIの認識結果（トップ10）\")\n",
        "             # Use change() for real-time updates from webcam\n",
        "             realtime_input.change(\n",
        "                 fn=classify_image_realtime,\n",
        "                 inputs=realtime_input,\n",
        "                 outputs=realtime_output,\n",
        "             )\n",
        "\n",
        "\n",
        "# 必要なライブラリのインストールを促すメッセージ\n",
        "print(\"\\nもし 'torch' や 'torchvision' がないというエラーが出たら、!pip install torch torchvision を実行してください。\")\n",
        "# アプリケーションの起動\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "p99xOJu6BCe8",
        "outputId": "6dc9bf9c-888e-4a7e-b95f-28ea05aa3774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIモデルの準備OK！\n",
            "アプリを起動します。URLが表示されたらクリックしてください。\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a6ecd06fab5fc0e1ee.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a6ecd06fab5fc0e1ee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 必要なライブラリをインポートします\n",
        "# gradio: Web UIを簡単に作るためのライブラリ\n",
        "# PIL (Pillow): 画像を加工するためのライブラリ\n",
        "# numpy: 数値計算、特にAIでよく使われるライブラリ\n",
        "# その他: AIモデルを動かすためのライブラリ\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "# --- ここからAIの準備 (この部分は完成しています) ---\n",
        "# 授業で使ったResNet50モデルとImageNetラベルを準備します\n",
        "# この部分は一度だけ実行されます\n",
        "try:\n",
        "    model = resnet50(pretrained=True)\n",
        "    model.eval()\n",
        "    response = requests.get(\"https://git.io/JJkYN\")\n",
        "    labels = response.text.split(\"\\n\")\n",
        "    print(\"AIモデルの準備OK！\")\n",
        "except Exception as e:\n",
        "    print(\"AIモデルの準備中にエラーが発生しました:\", e)\n",
        "    model = None\n",
        "    labels = None\n",
        "# --- AIの準備ここまで ---\n",
        "\n",
        "\n",
        "# --- 関数を定義するエリア ---\n",
        "\n",
        "# 【課題１】画像加工用の関数を完成させよう！\n",
        "# 1コマ目の最後に作った「白黒フィルター」の処理を思い出して書いてみよう！\n",
        "def image_filter(input_img):\n",
        "    print(\"画像加工ボタンが押されました！\")\n",
        "    if input_img is None:\n",
        "        return None # 画像がなければ何もしない\n",
        "\n",
        "    # ▼▼▼ ここに、Pillowを使った画像処理コードを追加しよう ▼▼▼\n",
        "    # ヒント: input_img.convert('L') を使うと白黒にできます\n",
        "\n",
        "    processed_img = input_img.convert('L') # 今はまだ何もしないので、この行を書き換えよう！\n",
        "\n",
        "    # ▲▲▲ ここまで ▲▲▲\n",
        "\n",
        "    return processed_img\n",
        "\n",
        "\n",
        "# 【課題２】AI分析用の関数を完成させよう！\n",
        "# 2コマ目に体験した「AIによる画像判定」のコードを参考に、中身を完成させよう！\n",
        "def predict_image(input_img):\n",
        "    print(\"AI分析ボタンが押されました！\")\n",
        "    if model is None or labels is None or input_img is None:\n",
        "        return \"AIモデルが準備できていないか、画像がありません。\"\n",
        "\n",
        "    # ▼▼▼ ここに、AIに画像を分析させるコードを追加しよう ▼▼▼\n",
        "    # ヒント: 教材『3.Gradio(Webインタフェース)の基本.ipynb』の最後の部分を参考にしよう\n",
        "    # 手順１：画像の前処理 (リサイズ、Tensorに変換、正規化)\n",
        "    # 手順２：AIによる推論 (model(img) を呼び出す)\n",
        "    # 手順３：結果を整形して、returnで返す\n",
        "    img = F.resize(input_img, (224, 224))\n",
        "    img = F.to_tensor(img)\n",
        "    if img.shape[0] == 1: # 白黒画像の場合\n",
        "        img = img.repeat(3, 1, 1)\n",
        "    img = F.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    # 推論の実行\n",
        "    with torch.no_grad():\n",
        "        output = model(img).squeeze(0)\n",
        "    probs = torch.nn.functional.softmax(output, dim=0).numpy()\n",
        "\n",
        "    # 結果を{ラベル: 確率}の辞書形式で返す\n",
        "    result = {labels[i]: float(probs[i]) for i in range(1000)} # 今はまだダミーのデータなので、この行を書き換えよう！\n",
        "\n",
        "    # ▲▲▲ ここまで ▲▲▲\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- Web UIを作るエリア (この部分は完成しています) ---\n",
        "# gr.Blocks() を使うと、より自由にUIを組み立てられます\n",
        "with gr.Blocks() as demo:\n",
        "    # アプリ全体のタイトル\n",
        "    gr.Markdown(\"# オリジナル画像加工＆AI分析アプリ\")\n",
        "\n",
        "    # gr.Tabs() で機能を切り替えるタブを作ります\n",
        "    with gr.Tabs():\n",
        "        # 1つ目のタブ\n",
        "        with gr.TabItem(\"画像加工フィルター\"):\n",
        "            gr.Markdown(\"## 好きな画像を加工してみよう！\")\n",
        "            with gr.Row():\n",
        "                # 左側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    image_input_filter = gr.Image(type=\"pil\", label=\"画像をアップロード\")\n",
        "                    process_button = gr.Button(\"加工する！\")\n",
        "                # 右側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    image_output_filter = gr.Image(label=\"加工後の画像\")\n",
        "\n",
        "            # ボタンが押されたら、どの関数を呼び出すか設定\n",
        "            process_button.click(fn=image_filter, inputs=image_input_filter, outputs=image_output_filter)\n",
        "\n",
        "        # 2つ目のタブ\n",
        "        with gr.TabItem(\"AI画像分析\"):\n",
        "            gr.Markdown(\"## AIが写真に写っているものを当てるよ！\")\n",
        "            with gr.Row():\n",
        "                # 左側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    image_input_ai = gr.Image(type=\"pil\", label=\"画像をアップロード\")\n",
        "                    predict_button = gr.Button(\"AIに分析してもらう！\")\n",
        "                # 右側に配置するUI部品\n",
        "                with gr.Column():\n",
        "                    # gr.LabelはAIの分析結果を表示するのに便利です\n",
        "                    label_output_ai = gr.Label(num_top_classes=3, label=\"分析結果\")\n",
        "\n",
        "            # ボタンが押されたら、どの関数を呼び出すか設定\n",
        "            predict_button.click(fn=predict_image, inputs=image_input_ai, outputs=label_output_ai)\n",
        "\n",
        "\n",
        "# アプリを起動します\n",
        "print(\"アプリを起動します。URLが表示されたらクリックしてください。\")\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOxVC/VkwsU6japUamdflVt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}